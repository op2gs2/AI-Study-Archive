{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from tqdm import tqdm # 반복 연산에 대한 진행 상황을 추적\n",
    "\n",
    "# 바이트를 벡터로 변환하는 임베딩 함수\n",
    "def embed_bytes(byte):\n",
    "    binary_string = f\"{byte:08b}\"\n",
    "    vec = np.zeros(8)\n",
    "    for i in range(8):\n",
    "        if binary_string[i] == '1':\n",
    "            vec[i] = float(1) / 16\n",
    "        else:\n",
    "            vec[i] = -float(1) / 16\n",
    "    return vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# 원시 PE 샘플의 위치를 읽어 레이블의 리스트를 만든다.\n",
    "directories_with_lables = [(\"Benign PE Samples\", 0), (\"Malicious PE Samples\", 1)]\n",
    "list_of_samples = []\n",
    "labels = []\n",
    "for dataset_path, label in directories_with_lables:\n",
    "    samples = [f for f in os.listdir(dataset_path)]\n",
    "    for file in samples:\n",
    "        file_path = os.path.join(dataset_path, file)\n",
    "        list_of_samples.append(file_path)\n",
    "        labels.append(label)\n",
    "        \n",
    "# 파일의 바이트 문자열을 읽을 편의 함수\n",
    "def read_file(file_path):\n",
    "    # 파일의 이진 문자열을 읽는다.\n",
    "    with open(file_path, \"rb\") as binary_file:\n",
    "        return binary_file.read()\n",
    "    \n",
    "# 샘플마다 읽을 바이트의 최대 길이(maxSize)를 설정\n",
    "# 샘플의 모든 바이트를 임베딩하고, 결과를 X에 모은다.\n",
    "max_size = 15000\n",
    "num_samples = len(list_of_samples)\n",
    "X = np.zeros((num_samples, 8, max_size))\n",
    "Y = np.asarray(labels)\n",
    "file_num = 0\n",
    "for file in tqdm(list_of_samples):\n",
    "    sample_byte_sequence = read_file(file)\n",
    "    for i in range(min(max_size, len(sample_byte_sequence))):\n",
    "        X[file_num, :, i] = embed_bytes(sample_byte_sequence[i])\n",
    "    file_num += 1"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Optimizer를 준비한다.\n",
    "from keras import optimizers\n",
    "\n",
    "my_opt = optimizers.SGD(lr=0.01, decay=1e-5, nesterov = True)\n",
    "\n",
    "# Keras를 이용해 심층 신경망 구조를 설정한다.\n",
    "from keras import Input\n",
    "from keras.layers import Conv1D, Activation, multiply, GlobalMaxPool1D, Dense\n",
    "from keras import Model\n",
    "\n",
    "inputs = Input(shape=(8, max_size))\n",
    "conv1 = Conv1D(kernel_size=128, filters=32, strides=128, padding='same')(inputs)\n",
    "conv2 = Conv1D(kernel_size=128, filters=32, strides=128, padding='same')(inputs)\n",
    "a = Activation('sigmoid', name='sigmoid')(conv2)\n",
    "mul = multiply([conv1, a])\n",
    "b = Activation('relu', name='relu')(mul)\n",
    "p = GlobalMaxPool1D()(b)\n",
    "d = Dense(16)(p)\n",
    "predictions = Dense(1, activation='sigmoid')(d)\n",
    "model = Model(inputs = inputs, outputs = predictions)\n",
    "\n",
    "# 모델을 컴파일하고, 배치 크기를 선택함.\n",
    "model.compile(optimizer=my_opt, loss=\"binary_crossentropy\", metrics=['acc'])\n",
    "batch_size = 16\n",
    "num_batches = int(num_samples / batch_size)\n",
    "\n",
    "# 배치에 대해 훈련을 진행한다.\n",
    "for batch_num in tqdm(range(num_batches)):\n",
    "    batch = X[batch_num * batch_size : (batch_num + 1) * batch_size]\n",
    "    model.train_on_batch(batch, Y[batch_num * batch_size : (batch_num + 1) * batch_size])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}