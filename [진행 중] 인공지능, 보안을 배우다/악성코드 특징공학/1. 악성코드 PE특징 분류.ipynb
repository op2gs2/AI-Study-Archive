{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "13900e77",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter the path of samples >> /mal\n",
      "Give file name of output file. >>q\n",
      "Enter type of sample( malware(1)|benign(0))>>1\n",
      "DEBUG <_io.TextIOWrapper name='q.csv' mode='w' encoding='UTF-8'>\n",
      "파일 크기:  168960\n",
      "hash:  2337089f5225107923bd963581f8ab1e\n",
      "Successfully Data extracted and written for c522418670b4efa6c754ea19bf18e60d31e8c17929038cd3f14317134230a6e6.\n",
      "Processed 1 files\n",
      "파일 크기:  786432\n",
      "hash:  11cf5ca49a6c354eb005fb24bdf6b1f0\n",
      "Successfully Data extracted and written for 4e87a0794bf73d06ac1ce4a37e33eb832ff4c89fb9e4266490c7cef9229d27a7.\n",
      "Processed 2 files\n",
      "파일 크기:  830728\n",
      "hash:  b315c590c3ad691604597ea41f8dd84e\n",
      "Successfully Data extracted and written for 37ea273266aa2d28430194fca27849170d609d338abc9c6c43c4e6be1bcf51f9.\n",
      "Processed 3 files\n",
      "파일 크기:  829392\n",
      "hash:  78c9e98f51994a7af369db9a9ed6cdf9\n",
      "Successfully Data extracted and written for 45a4bd970485ca539c95d746fbe8866f868972dcf7f1d196199ed7ea8b50be5b.\n",
      "Processed 4 files\n",
      "파일 크기:  403968\n",
      "hash:  7fcbff331b40e7edcd4985a65a9ab621\n",
      "Successfully Data extracted and written for 358a5079b824548ef87fcf89d3e4b5284e780edc4de8a450f3e51878d1290eca.\n",
      "Processed 5 files\n",
      "파일 크기:  497664\n",
      "hash:  bf340b3ff326cede17c688bc4092a27b\n",
      "Successfully Data extracted and written for 7682b842ed75b69e23c5deecf05a45ee79c723d98cfb6746380d748145bfc1af.\n",
      "Processed 6 files\n",
      "파일 크기:  931043\n",
      "hash:  c1736b814389cb6602329186c8181b35\n",
      "Successfully Data extracted and written for a50f1be63ef1f51feac8f36a1b03664c4b6e8914633f6d71c5c7007984caf93c.\n",
      "Processed 7 files\n",
      "파일 크기:  92672\n",
      "hash:  6b645fbf570f4d09f059d8fed734fa3e\n",
      "Successfully Data extracted and written for 2573b356452dd5ee24c10537fa4848d882fa40a2a8fa5a181624ba460e1f769a.\n",
      "Processed 8 files\n",
      "파일 크기:  484320\n",
      "hash:  2a31d25952754a23c79bd127be09c74e\n",
      "Successfully Data extracted and written for e796e64c5f9a7568773bd2924e992172f222957e039ab7b41ade44865d0a48e5.\n",
      "Processed 9 files\n",
      "파일 크기:  467032\n",
      "hash:  0c725cb728834cf1a3cc041f09d1975a\n",
      "Successfully Data extracted and written for b4d73b07aa627674b03f9c96dd5883dcd78b73e5baba6426dcc87ff0e771b265.\n",
      "Processed 10 files\n",
      "파일 크기:  430080\n",
      "hash:  1517814c4d44cc632abb52d2d6307f15\n",
      "Successfully Data extracted and written for 91bfa2445d998425c81f30d293235429ca6a8c6c8f326536478952a2a6754aac.\n",
      "Processed 11 files\n",
      "파일 크기:  614400\n",
      "hash:  1720b1748ad7b8ac0bfc1c3636fead95\n",
      "Successfully Data extracted and written for 3329641a171508fa6b1ad7674b31431093d46be190d1a51acd77e486f42d9c8e.\n",
      "Processed 12 files\n",
      "파일 크기:  826120\n",
      "hash:  931679cff2703ea3ac1cb37cafa688a4\n",
      "Successfully Data extracted and written for 775c7bd9e820c4dfd0fabdfeade2de901414bd46d2691ea5020a818f6a42eb83.\n",
      "Processed 13 files\n",
      "파일 크기:  279552\n",
      "hash:  1cd13c94f70a672f8dc30be37ba93232\n",
      "Successfully Data extracted and written for 6f9fcfaa7d942dea200107857c51c4fbcd7ac5922f090a1b9dc91e0e67e03fa3.\n",
      "Processed 14 files\n",
      "파일 크기:  218112\n",
      "hash:  942ec5f51a5d46461d0e311dbd48c9a8\n",
      "Successfully Data extracted and written for b9079fb0fff9f40d7b5544f29d260b1659d8fcf019deadc72ec2c12882203a66.\n",
      "Processed 15 files\n",
      "파일 크기:  1124864\n",
      "hash:  f7f866371543363a694b8a6f0c5e2c13\n",
      "Successfully Data extracted and written for c0242d686b4c1707f9db2eb5afdd306507ceb5637d72662dff56c439330dbdf1.\n",
      "Processed 16 files\n",
      "파일 크기:  91648\n",
      "hash:  7714fccf2d8f60a76f2f77ba55666437\n",
      "Successfully Data extracted and written for 2f3409bb36d5411d1a02ebd189c305e2b20f744c204f15eef9be459ec398448b.\n",
      "Processed 17 files\n",
      "'DOS Header magic not found.' while opening /mal/0032588b8d93a807cf0f48a806ccf125677503a6fabe4105a6dc69e81ace6091\n",
      "hash:  dde72ae232dc63298465861482d7bb93\n",
      "Successfully Data extracted and written for 0032588b8d93a807cf0f48a806ccf125677503a6fabe4105a6dc69e81ace6091.\n",
      "Processed 18 files\n",
      "파일 크기:  193536\n",
      "hash:  060012602de8ee4f3df9b93657009555\n",
      "Successfully Data extracted and written for c140c8dc1453d7213da39a5020d6c90ef00d00491bb769cb762d6cc7c64372e7.\n",
      "Processed 19 files\n",
      "파일 크기:  322560\n",
      "hash:  d29866c8612fcda8e4f9d684d70dd8bb\n",
      "Successfully Data extracted and written for cc13afd5ffdd769c66118f4f5eec7f80655c14cfdc6e8b753e419bbfbea4784e.\n",
      "Processed 20 files\n",
      "파일 크기:  92672\n",
      "hash:  86c20760edac3503e9cbffb18e9c0ffd\n",
      "Successfully Data extracted and written for eaf3a35a01a43d0be584a1418126e1203836f874b7c9517ebceada3068b6b62c.\n",
      "Processed 21 files\n",
      "파일 크기:  528384\n",
      "hash:  c953aec897f1f624f4a0ea010e929442\n",
      "Successfully Data extracted and written for a5672f1287903b21f8fe4bd1851487e8ab37b380a6a78fc050cfbc2285daf8bc.\n",
      "Processed 22 files\n",
      "파일 크기:  935640\n",
      "hash:  31a6132927eca616227c650802d97301\n",
      "Successfully Data extracted and written for 2030f0f9fa95e6e824d12664b48344c6e4fd58e607c96e6300c88a8292d1f743.\n",
      "Processed 23 files\n",
      "파일 크기:  411982\n",
      "hash:  0c4374d72e166f15acdfe44e9398d026\n",
      "Successfully Data extracted and written for 240387329dee4f03f98a89a2feff9bf30dcba61fcf614cdac24129da54442762.\n",
      "Processed 24 files\n",
      "파일 크기:  2408940\n",
      "hash:  a7252f5fb605f7bc63b55d69bef1a2ec\n",
      "Successfully Data extracted and written for 3a411c1f2e55d7e21318a32d1527f8ebd7ab76d873368acbb573e67b89257f5e.\n",
      "Processed 25 files\n",
      "파일 크기:  146432\n",
      "hash:  74622fbc3aae349b7771709444183314\n",
      "Successfully Data extracted and written for 785872bbef35d86fe6ce8a53be29995cfd0f251d2a171145bd6685bebe63ebc8.\n",
      "Processed 26 files\n",
      "파일 크기:  2177536\n",
      "hash:  c22908fe460312d76b50129aa3ef2cf2\n",
      "Successfully Data extracted and written for 46f79c451e652fc4ce7ad5a6f9eb737642077c128e514c889458220ed6985913.\n",
      "Processed 27 files\n",
      "File Processing Complete!!\n"
     ]
    }
   ],
   "source": [
    "'''본 코드를 구동하기 위한 패키지 설치'''\n",
    "# pip install pefile\n",
    "# pip install yara\n",
    "'''PE 특징 분석을 위한 yara파일 설정'''\n",
    "# find / -name libyara.so \n",
    "# cp LIB_YARA_PATH /home/stud/anaconda3/envs/mldlsec_310/lib/\n",
    "# yara file comes from here: https://github.com/urwithajit9/ClaMP\n",
    "\n",
    "import csv,os,pefile\n",
    "import yara\n",
    "import math\n",
    "import hashlib\n",
    "\n",
    "class pe_features():\n",
    "\n",
    "    IMAGE_DOS_HEADER = [\n",
    "                        \"e_cblp\",\\\n",
    "                        \"e_cp\", \\\n",
    "                        \"e_cparhdr\",\\\n",
    "                        \"e_maxalloc\",\\\n",
    "                        \"e_sp\",\\\n",
    "                        \"e_lfanew\"]\n",
    "\n",
    "    FILE_HEADER= [\"NumberOfSections\",\"CreationYear\"] + [ \"FH_char\" + str(i) for i in range(15)]\n",
    "                \n",
    "\n",
    "    OPTIONAL_HEADER1 = [\n",
    "                        \"MajorLinkerVersion\",\\\n",
    "                        \"MinorLinkerVersion\",\\\n",
    "                        \"SizeOfCode\",\\\n",
    "                        \"SizeOfInitializedData\",\\\n",
    "                        \"SizeOfUninitializedData\",\\\n",
    "                        \"AddressOfEntryPoint\",\\\n",
    "                        \"BaseOfCode\",\\\n",
    "                        \"BaseOfData\",\\\n",
    "                        \"ImageBase\",\\\n",
    "                        \"SectionAlignment\",\\\n",
    "                        \"FileAlignment\",\\\n",
    "                        \"MajorOperatingSystemVersion\",\\\n",
    "                        \"MinorOperatingSystemVersion\",\\\n",
    "                        \"MajorImageVersion\",\\\n",
    "                        \"MinorImageVersion\",\\\n",
    "                        \"MajorSubsystemVersion\",\\\n",
    "                        \"MinorSubsystemVersion\",\\\n",
    "                        \"SizeOfImage\",\\\n",
    "                        \"SizeOfHeaders\",\\\n",
    "                        \"CheckSum\",\\\n",
    "                        \"Subsystem\"] \n",
    "    OPTIONAL_HEADER_DLL_char = [ \"OH_DLLchar\" + str(i) for i in range(11)]                   \n",
    "                            \n",
    "    OPTIONAL_HEADER2 = [\n",
    "                        \"SizeOfStackReserve\",\\\n",
    "                        \"SizeOfStackCommit\",\\\n",
    "                        \"SizeOfHeapReserve\",\\\n",
    "                        \"SizeOfHeapCommit\",\\\n",
    "                        \"LoaderFlags\"]  # boolean check for zero or not\n",
    "    OPTIONAL_HEADER = OPTIONAL_HEADER1 + OPTIONAL_HEADER_DLL_char + OPTIONAL_HEADER2\n",
    "    Derived_header = [\"sus_sections\",\"non_sus_sections\", \"packer\",\"packer_type\",\"E_text\",\"E_data\",\"filesize\",\"E_file\",\"fileinfo\"]\n",
    "    \n",
    "    # 클래스의 생성자\n",
    "    def __init__(self,source,output,label):\n",
    "        self.source = source\n",
    "        self.output = output\n",
    "        self.type = label\n",
    "\t#Need PEiD rules compile with yara\n",
    "        self.rules= yara.compile(filepath='./peid.yara')\n",
    "        \n",
    "    def file_creation_year(self,seconds):\n",
    "        tmp = 1970 + ((int(seconds) / 86400) / 365)\n",
    "        return int(tmp in range (1980,2016)) \n",
    "\n",
    "    def FILE_HEADER_Char_boolean_set(self,pe):\n",
    "        tmp = [pe.FILE_HEADER.IMAGE_FILE_RELOCS_STRIPPED,\\\n",
    "            pe.FILE_HEADER.IMAGE_FILE_EXECUTABLE_IMAGE,\\\n",
    "            pe.FILE_HEADER.IMAGE_FILE_LINE_NUMS_STRIPPED,\\\n",
    "            pe.FILE_HEADER.IMAGE_FILE_LOCAL_SYMS_STRIPPED,\\\n",
    "            pe.FILE_HEADER.IMAGE_FILE_AGGRESIVE_WS_TRIM,\\\n",
    "            pe.FILE_HEADER.IMAGE_FILE_LARGE_ADDRESS_AWARE,\\\n",
    "            pe.FILE_HEADER.IMAGE_FILE_BYTES_REVERSED_LO,\\\n",
    "            pe.FILE_HEADER.IMAGE_FILE_32BIT_MACHINE,\\\n",
    "            pe.FILE_HEADER.IMAGE_FILE_DEBUG_STRIPPED,\\\n",
    "            pe.FILE_HEADER.IMAGE_FILE_REMOVABLE_RUN_FROM_SWAP,\\\n",
    "            pe.FILE_HEADER.IMAGE_FILE_NET_RUN_FROM_SWAP,\\\n",
    "            pe.FILE_HEADER.IMAGE_FILE_SYSTEM,\\\n",
    "            pe.FILE_HEADER.IMAGE_FILE_DLL,\\\n",
    "            pe.FILE_HEADER.IMAGE_FILE_UP_SYSTEM_ONLY,\\\n",
    "            pe.FILE_HEADER.IMAGE_FILE_BYTES_REVERSED_HI\n",
    "            ]\n",
    "        return [int(s) for s in tmp]\n",
    "\n",
    "    def OPTIONAL_HEADER_DLLChar(self,pe):\n",
    "        tmp = [\n",
    "            pe.OPTIONAL_HEADER.IMAGE_DLLCHARACTERISTICS_DYNAMIC_BASE,\\\n",
    "            pe.OPTIONAL_HEADER.IMAGE_DLLCHARACTERISTICS_FORCE_INTEGRITY,\\\n",
    "            pe.OPTIONAL_HEADER.IMAGE_DLLCHARACTERISTICS_NX_COMPAT ,\\\n",
    "            pe.OPTIONAL_HEADER.IMAGE_DLLCHARACTERISTICS_NO_ISOLATION,\\\n",
    "            pe.OPTIONAL_HEADER.IMAGE_DLLCHARACTERISTICS_NO_SEH,\\\n",
    "            pe.OPTIONAL_HEADER.IMAGE_DLLCHARACTERISTICS_NO_BIND,\\\n",
    "            pe.OPTIONAL_HEADER.IMAGE_DLLCHARACTERISTICS_WDM_DRIVER,\\\n",
    "            pe.OPTIONAL_HEADER.IMAGE_DLLCHARACTERISTICS_TERMINAL_SERVER_AWARE,\\\n",
    "            pe.OPTIONAL_HEADER.IMAGE_DLLCHARACTERISTICS_HIGH_ENTROPY_VA,\\\n",
    "            pe.OPTIONAL_HEADER.IMAGE_DLLCHARACTERISTICS_APPCONTAINER,\\\n",
    "            pe.OPTIONAL_HEADER.IMAGE_DLLCHARACTERISTICS_GUARD_CF\n",
    "            ]\n",
    "        return [int(s) for s in tmp]\n",
    "\n",
    "    def Optional_header_ImageBase(self,ImageBase):\n",
    "        result= 0\n",
    "        if ImageBase % (64 * 1024) == 0 and ImageBase in [268435456,65536,4194304]:\n",
    "            result = 1\n",
    "        return result\n",
    "\n",
    "    def Optional_header_SectionAlignment(self,SectionAlignment,FileAlignment):\n",
    "        \"\"\"This is boolean function and will return 0 or 1 based on condidtions\n",
    "        that it SectionAlignment must be greater than or equal to FileAlignment\n",
    "        \"\"\"\n",
    "        return int(SectionAlignment >= FileAlignment)\n",
    "\n",
    "    def Optional_header_FileAlignment(self,SectionAlignment,FileAlignment):\n",
    "        result =0\n",
    "        if SectionAlignment >= 512:\n",
    "            if FileAlignment % 2 == 0 and FileAlignment in range(512,65537):\n",
    "                result =1\n",
    "        else: \n",
    "            if FileAlignment == SectionAlignment:\n",
    "                result = 1\n",
    "        return result\n",
    "\n",
    "    def Optional_header_SizeOfImage(self,SizeOfImage,SectionAlignment):\n",
    "\n",
    "        return int(SizeOfImage % SectionAlignment == 0)\n",
    "\n",
    "    def Optional_header_SizeOfHeaders(self,SizeOfHeaders,FileAlignment):\n",
    "\n",
    "        return int(SizeOfHeaders % FileAlignment == 0 )\n",
    "\n",
    "    def extract_dos_header(self,pe):\n",
    "        IMAGE_DOS_HEADER_data = [ 0 for i in range(6)]\n",
    "        try:\n",
    "            IMAGE_DOS_HEADER_data = [\n",
    "                                pe.DOS_HEADER.e_cblp,\\\n",
    "                                pe.DOS_HEADER.e_cp, \\\n",
    "                                pe.DOS_HEADER.e_cparhdr,\\\n",
    "                                pe.DOS_HEADER.e_maxalloc,\\\n",
    "                                pe.DOS_HEADER.e_sp,\\\n",
    "                                pe.DOS_HEADER.e_lfanew]\n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "        return IMAGE_DOS_HEADER_data\n",
    "\n",
    "    def extract_file_header(self,pe):\t\n",
    "        FILE_HEADER_data = [ 0 for i in range(3)]\n",
    "        FILE_HEADER_char =  []\n",
    "        try:\n",
    "            FILE_HEADER_data = [ \n",
    "                    pe.FILE_HEADER.NumberOfSections, \\\n",
    "                    self.file_creation_year(pe.FILE_HEADER.TimeDateStamp)]\n",
    "            FILE_HEADER_char = self.FILE_HEADER_Char_boolean_set(pe)\n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "        return FILE_HEADER_data + FILE_HEADER_char\n",
    "\n",
    "    def extract_optional_header(self,pe):\n",
    "        OPTIONAL_HEADER_data = [ 0 for i in range(21)]\n",
    "        DLL_char =[]\n",
    "        OPTIONAL_HEADER_data2 = [ 0 for i in range(6)]\n",
    "\n",
    "        try:\n",
    "            OPTIONAL_HEADER_data = [\n",
    "                pe.OPTIONAL_HEADER.MajorLinkerVersion,\\\n",
    "                pe.OPTIONAL_HEADER.MinorLinkerVersion,\\\n",
    "                pe.OPTIONAL_HEADER.SizeOfCode,\\\n",
    "                pe.OPTIONAL_HEADER.SizeOfInitializedData,\\\n",
    "                pe.OPTIONAL_HEADER.SizeOfUninitializedData,\\\n",
    "                pe.OPTIONAL_HEADER.AddressOfEntryPoint,\\\n",
    "                pe.OPTIONAL_HEADER.BaseOfCode,\\\n",
    "                pe.OPTIONAL_HEADER.BaseOfData,\\\n",
    "                #Check the ImageBase for the condition\n",
    "                self.Optional_header_ImageBase(pe.OPTIONAL_HEADER.ImageBase),\\\n",
    "                # Checking for SectionAlignment condition\n",
    "                self.Optional_header_SectionAlignment(pe.OPTIONAL_HEADER.SectionAlignment,pe.OPTIONAL_HEADER.FileAlignment),\\\n",
    "                #Checking for FileAlignment condition\n",
    "                self.Optional_header_FileAlignment(pe.OPTIONAL_HEADER.SectionAlignment,pe.OPTIONAL_HEADER.FileAlignment),\\\n",
    "                pe.OPTIONAL_HEADER.MajorOperatingSystemVersion,\\\n",
    "                pe.OPTIONAL_HEADER.MinorOperatingSystemVersion,\\\n",
    "                pe.OPTIONAL_HEADER.MajorImageVersion,\\\n",
    "                pe.OPTIONAL_HEADER.MinorImageVersion,\\\n",
    "                pe.OPTIONAL_HEADER.MajorSubsystemVersion,\\\n",
    "                pe.OPTIONAL_HEADER.MinorSubsystemVersion,\\\n",
    "                #Checking size of Image\n",
    "                self.Optional_header_SizeOfImage(pe.OPTIONAL_HEADER.SizeOfImage,pe.OPTIONAL_HEADER.SectionAlignment),\\\n",
    "                #Checking for size of headers\n",
    "                self.Optional_header_SizeOfHeaders(pe.OPTIONAL_HEADER.SizeOfHeaders,pe.OPTIONAL_HEADER.FileAlignment),\\\n",
    "                pe.OPTIONAL_HEADER.CheckSum,\\\n",
    "                pe.OPTIONAL_HEADER.Subsystem]\n",
    "\n",
    "            DLL_char = self.OPTIONAL_HEADER_DLLChar(pe)\n",
    "\n",
    "            OPTIONAL_HEADER_data2= [                \n",
    "                pe.OPTIONAL_HEADER.SizeOfStackReserve,\\\n",
    "                pe.OPTIONAL_HEADER.SizeOfStackCommit,\\\n",
    "                pe.OPTIONAL_HEADER.SizeOfHeapReserve,\\\n",
    "                pe.OPTIONAL_HEADER.SizeOfHeapCommit,\\\n",
    "                int(pe.OPTIONAL_HEADER.LoaderFlags == 0) ]\n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "        return OPTIONAL_HEADER_data + DLL_char + OPTIONAL_HEADER_data2\n",
    "    \n",
    "    # 섹션 이름을 검사함 (정상/악성코드에서 많이 보이는 섹션 이름을 확인)\n",
    "    def get_count_suspicious_sections(self,pe):\n",
    "        result=[]\n",
    "        tmp =[]\n",
    "        tmp_str = ''\n",
    "        benign_sections = set(['.text','.data','.rdata','.idata','.edata','.rsrc','.bss','.crt','.tls'])\n",
    "        for section in pe.sections:\n",
    "            # [수정사항] section.Name은 별도의 객체이므로, 디코딩 후 Split()을 할 수 있다.\n",
    "            # 따라서, 디코딩 -> split() -> 인코딩을 거쳐 바이트 문자열을 편집한다.\n",
    "            tmp_str = section.Name.decode('utf-8')\n",
    "            tmp_str = tmp_str.split('\\x00')[0]\n",
    "            tmp_str = tmp_str.encode('utf-8')\n",
    "            tmp.append(tmp_str)\n",
    "        non_sus_sections = len(set(tmp).intersection(benign_sections))\n",
    "        result=[len(tmp) - non_sus_sections, non_sus_sections]\n",
    "        return result\n",
    "\n",
    "    # 파일에 적용된 패커 알고리즘을 검사(yara 룰셋의 시그니처 활용)\n",
    "    def check_packer(self,filepath):\n",
    "\n",
    "        result=[]\n",
    "        matches = self.rules.match(filepath)\n",
    "\n",
    "        try:\n",
    "            if matches == [] or matches == {}:\n",
    "                result.append([0,\"NoPacker\"])\n",
    "            else:\n",
    "                result.append([1,matches['main'][0]['rule']])\n",
    "        except:\n",
    "            result.append([1,matches[0]])\n",
    "\n",
    "        return result\n",
    "\n",
    "    # 코드와 데이터 섹션의 엔트로피 계산\n",
    "    def get_text_data_entropy(self,pe):\n",
    "        result=[0.0,0.0]\n",
    "        for section in pe.sections:\n",
    "            # [수정사항] section.Name은 별도의 객체이므로, 디코딩 후 Split()을 할 수 있다.\n",
    "            # 따라서, 디코딩 -> split() -> 인코딩을 거쳐 바이트 문자열을 편집한다.\n",
    "            tmp_str = section.Name.decode('utf-8')\n",
    "            tmp_str = tmp_str.split('\\x00')[0]\n",
    "            s_name = tmp_str.encode('utf-8')\n",
    "            if s_name == \".text\":\n",
    "                result[0]= section.get_entropy()\n",
    "            elif s_name == \".data\":\n",
    "                result[1]= section.get_entropy()\n",
    "            else:\n",
    "                pass\n",
    "        return result  \n",
    "\n",
    "    #  파일 전체의 엔트로피 값 계산\n",
    "    def get_file_bytes_size(self,filepath):\n",
    "        # [수정사항] map은 len()을 쓸 수 없다.\n",
    "        # 따라서, 파일을 바이트모드로 연 다음, 리스트에 저장했다.\n",
    "        # 그 다음, 리스트의 길이를 측정하여 파일크기를 측정했다.\n",
    "        with open(filepath, \"rb\") as f:\n",
    "            byteArr = list(f.read())\n",
    "        f.close()\n",
    "        fileSize = len(byteArr)\n",
    "        print(\"파일 크기: \",fileSize)\n",
    "        return byteArr,fileSize\n",
    "\n",
    "    def cal_byteFrequency(self,byteArr,fileSize):\n",
    "        freqList = []\n",
    "        for b in range(256):\n",
    "            ctr = 0\n",
    "            for byte in byteArr:\n",
    "                if byte == b:\n",
    "                    ctr += 1\n",
    "            freqList.append(float(ctr) / fileSize)\n",
    "        return freqList\n",
    "\n",
    "    # 파일 전체의 엔트로피 계산\n",
    "    def get_file_entropy(self,filepath):\n",
    "        byteArr, fileSize = self.get_file_bytes_size(filepath)\n",
    "        freqList = self.cal_byteFrequency(byteArr,fileSize)\n",
    "        # Shannon entropy\n",
    "        ent = 0.0\n",
    "        for freq in freqList:\n",
    "            if freq > 0:\n",
    "                ent +=  - freq * math.log(freq, 2)\n",
    "\n",
    "            #ent = -ent\n",
    "        return [fileSize,ent]\n",
    "\n",
    "    # 파일 버전, 제품버전, 제품이름, 회사 이름을 조회\n",
    "    def get_fileinfo(self,pe):\n",
    "        result=[]\n",
    "        try:\n",
    "            FileVersion    = pe.FileInfo[0].StringTable[0].entries['FileVersion']\n",
    "            ProductVersion = pe.FileInfo[0].StringTable[0].entries['ProductVersion']\n",
    "            ProductName =    pe.FileInfo[0].StringTable[0].entries['ProductName']\n",
    "            CompanyName = pe.FileInfo[0].StringTable[0].entries['CompanyName']\n",
    "        #getting Lower and \n",
    "            FileVersionLS    = pe.VS_FIXEDFILEINFO.FileVersionLS\n",
    "            FileVersionMS    = pe.VS_FIXEDFILEINFO.FileVersionMS\n",
    "            ProductVersionLS = pe.VS_FIXEDFILEINFO.ProductVersionLS\n",
    "            ProductVersionMS = pe.VS_FIXEDFILEINFO.ProductVersionMS\n",
    "        except Exception as e:\n",
    "            result=[\"error\"]\n",
    "        #print \"{} while opening {}\".format(e,filepath)\n",
    "        else:\n",
    "        #shifting byte\n",
    "            FileVersion = (FileVersionMS >> 16, FileVersionMS & 0xFFFF, FileVersionLS >> 16, FileVersionLS & 0xFFFF)\n",
    "            ProductVersion = (ProductVersionMS >> 16, ProductVersionMS & 0xFFFF, ProductVersionLS >> 16, ProductVersionLS & 0xFFFF)\n",
    "            result = [FileVersion,ProductVersion,ProductName,CompanyName]\n",
    "        return int ( result[0] != 'error')\n",
    "\n",
    "    def write_csv_header(self):\n",
    "        filepath = self.output + \".csv\"\n",
    "        HASH = ['filename(SHA-256)', 'MD5']\n",
    "        header = HASH + self.IMAGE_DOS_HEADER + self.FILE_HEADER + self.OPTIONAL_HEADER + self.Derived_header\n",
    "        header.append(\"class\")\n",
    "        csv_file = open(filepath, 'w')\n",
    "        print(\"DEBUG\",csv_file)\n",
    "        writer = csv.writer(csv_file, delimiter=',')\n",
    "        writer.writerow(header)\n",
    "        csv_file.close()\n",
    "\n",
    "    # 코드의 Feature를 추출하는 함수\n",
    "    def extract_all(self,filepath):\n",
    "        data =[]\n",
    "        #load given file\n",
    "        try:\n",
    "            pe = pefile.PE(filepath)\n",
    "        except Exception as e:\n",
    "            print(\"{} while opening {}\".format(e,filepath))\n",
    "        else:\n",
    "            # 단순 파싱으로 뽑아낼 수 있는 정보를 추출함 (Raw Features)\n",
    "            data += self.extract_dos_header(pe)\n",
    "            data += self.extract_file_header(pe)\n",
    "            data += self.extract_optional_header(pe)\n",
    "            # 필드 값의 의미를 한 번 더 해석해 특징 추출 (derived features)\n",
    "            #number of suspicisou sections and non-suspicsious section\n",
    "            num_ss_nss = self.get_count_suspicious_sections(pe)\n",
    "            data += num_ss_nss\n",
    "            # check for packer and packer type\n",
    "            packer = self.check_packer(filepath)\n",
    "\n",
    "            # Appending the packer info to the rest of features\n",
    "            data += packer[0]\n",
    "            entropy_sections = self.get_text_data_entropy(pe)\n",
    "            data += entropy_sections\n",
    "            f_size_entropy = self.get_file_entropy(filepath)\n",
    "            data += f_size_entropy\n",
    "            fileinfo = self.get_fileinfo(pe)\n",
    "            data.append(fileinfo)\n",
    "            data.append(self.type)\n",
    "        \n",
    "        return data  \n",
    "\n",
    "    def write_csv_data(self,data):\n",
    "        filepath = self.output\n",
    "        csv_file= open(filepath,\"a\")\n",
    "        writer = csv.writer(csv_file, delimiter=',')\n",
    "        writer.writerow(data)\n",
    "        csv_file.close()\n",
    "\n",
    "    def getMD5(self, filepath):\n",
    "        with open(filepath, 'rb') as fh:\n",
    "            m = hashlib.md5()\n",
    "            while True:\n",
    "                data = fh.read(8192)\n",
    "                if not data:\n",
    "                    break\n",
    "                m.update(data)\n",
    "            return m.hexdigest()\n",
    "\n",
    "    def create_dataset(self):\n",
    "        self.write_csv_header() # CSV 헤더 생성\n",
    "        count = 0\n",
    "\n",
    "        #run through all file of source and extract features\n",
    "        for file in os.listdir(self.source):      # source_path로 지정한 경로의 모든 파일을 가져옴   \n",
    "                filepath = self.source + \"/\" + file \n",
    "                data = self.extract_all(filepath) # 특징 추출 함수\n",
    "                hash_ = self.getMD5(filepath)\n",
    "                print(\"hash: \", hash_)\n",
    "                data.insert(0, hash_)\n",
    "                data.insert(0, file)\n",
    "\n",
    "                self.write_csv_data(data)\n",
    "                count += 1\n",
    "                print(\"Successfully Data extracted and written for {}.\".format(file))\n",
    "                print(\"Processed \" + str(count) + \" files\")\n",
    "        print(\"File Processing Complete!!\")\n",
    "\n",
    "def main():   \n",
    "    # 샘플파일이 위치하는 경로\n",
    "    source_path= input(\"Enter the path of samples >> \")\n",
    "    # 특징 추출 결과를 저장할 CSV 파일 이름\n",
    "    output_file= input(\"Give file name of output file. >>\")\n",
    "    # 라벨링: 악성코드인 경우 1, 정상 프로그램은 0\n",
    "    label = input(\"Enter type of sample( malware(1)|benign(0))>>\")\n",
    "    features = pe_features(source_path,output_file,label)    \n",
    "    features.create_dataset()\n",
    "    \n",
    "if __name__ == '__main__':\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdc5a471",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mldlsec_310",
   "language": "python",
   "name": "mldlsec_310"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
