{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "80d5af58",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''데이터 불러오기'''\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# 파일로부터 데이터 읽어들이기\n",
    "read_formula_data = pd.read_csv('../1. 초기데이터/Data_Set_LDL-C-formula.csv')\n",
    "read_dnn_data = pd.read_csv('../1. 초기데이터/Data_Set_LDL-C-DNN.csv')\n",
    "read_val_set_data = pd.read_csv('../1. 초기데이터/Data_Set_LDL-C_valset.csv')\n",
    "\n",
    "# 각 유형별 데이터로 정리하기: 방정식, DNN\n",
    "fridewald_data = np.array(read_formula_data.iloc[:,1])\n",
    "marin_data = np.array(read_formula_data.iloc[:,2])\n",
    "simpson_data = np.array(read_formula_data.iloc[:,3])\n",
    "dnn_data = np.array(read_dnn_data.iloc[:,1])\n",
    "\n",
    "# 각 유형별 데이터로 정리하기: LDL_C, TG\n",
    "LDL_C_data = np.array(read_val_set_data.iloc[:,5])\n",
    "TG_data = np.array(read_val_set_data.iloc[:,6])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f222c9f2",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '../3. 초기데이터/0. 데이터/fridewald 회귀분석 데이터.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_9348/3656360384.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[1;31m# 유형별로 회귀분석 데이터 저장\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[0mdf_save\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconcat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mdf_LDL_C\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdf_fridewald_predicted\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 12\u001b[1;33m \u001b[0mdf_save\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'../3. 초기데이터/0. 데이터/fridewald 회귀분석 데이터.csv'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     13\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[0mdf_save\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconcat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mdf_LDL_C\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdf_marin_predicted\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Programs\\Anaconda\\envs\\tensor-gpu\\lib\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36mto_csv\u001b[1;34m(self, path_or_buf, sep, na_rep, float_format, columns, header, index, index_label, mode, encoding, compression, quoting, quotechar, line_terminator, chunksize, date_format, doublequote, escapechar, decimal, errors, storage_options)\u001b[0m\n\u001b[0;32m   3480\u001b[0m             \u001b[0mdoublequote\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdoublequote\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3481\u001b[0m             \u001b[0mescapechar\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mescapechar\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3482\u001b[1;33m             \u001b[0mstorage_options\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mstorage_options\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3483\u001b[0m         )\n\u001b[0;32m   3484\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Programs\\Anaconda\\envs\\tensor-gpu\\lib\\site-packages\\pandas\\io\\formats\\format.py\u001b[0m in \u001b[0;36mto_csv\u001b[1;34m(self, path_or_buf, encoding, sep, columns, index_label, mode, compression, quoting, quotechar, line_terminator, chunksize, date_format, doublequote, escapechar, errors, storage_options)\u001b[0m\n\u001b[0;32m   1103\u001b[0m             \u001b[0mformatter\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfmt\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1104\u001b[0m         )\n\u001b[1;32m-> 1105\u001b[1;33m         \u001b[0mcsv_formatter\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msave\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1106\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1107\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcreated_buffer\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Programs\\Anaconda\\envs\\tensor-gpu\\lib\\site-packages\\pandas\\io\\formats\\csvs.py\u001b[0m in \u001b[0;36msave\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    241\u001b[0m             \u001b[0merrors\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0merrors\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    242\u001b[0m             \u001b[0mcompression\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcompression\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 243\u001b[1;33m             \u001b[0mstorage_options\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstorage_options\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    244\u001b[0m         ) as handles:\n\u001b[0;32m    245\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Programs\\Anaconda\\envs\\tensor-gpu\\lib\\site-packages\\pandas\\io\\common.py\u001b[0m in \u001b[0;36mget_handle\u001b[1;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[0;32m    705\u001b[0m                 \u001b[0mencoding\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mioargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mencoding\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    706\u001b[0m                 \u001b[0merrors\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0merrors\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 707\u001b[1;33m                 \u001b[0mnewline\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    708\u001b[0m             )\n\u001b[0;32m    709\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '../3. 초기데이터/0. 데이터/fridewald 회귀분석 데이터.csv'"
     ]
    }
   ],
   "source": [
    "'''회귀분석 데이터 생성'''\n",
    "\n",
    "# 각 데이터에 헤더 정보를 추가\n",
    "df_fridewald_predicted = pd.DataFrame(fridewald_data ,columns=['fridewald_predicted'])\n",
    "df_marin_predicted = pd.DataFrame(marin_data ,columns=['marin_predicted'])\n",
    "df_simpson_predicted = pd.DataFrame(simpson_data ,columns=['simpson_predicted'])\n",
    "df_dnn_predicted = pd.DataFrame(dnn_data ,columns=['dnn_predicted'])\n",
    "df_LDL_C = pd.DataFrame(LDL_C_data ,columns=['LDL_C'])\n",
    "\n",
    "# 유형별로 회귀분석 데이터 저장\n",
    "df_save = pd.concat([df_LDL_C, df_fridewald_predicted], axis = 1)\n",
    "df_save.to_csv('../3. 초기데이터/0. 데이터/fridewald 회귀분석 데이터.csv', index=False)\n",
    "\n",
    "df_save = pd.concat([df_LDL_C, df_marin_predicted], axis = 1)\n",
    "df_save.to_csv('../3. 초기데이터/0. 데이터/marin 회귀분석 데이터.csv', index=False)\n",
    "\n",
    "df_save = pd.concat([df_LDL_C, df_simpson_predicted], axis = 1)\n",
    "df_save.to_csv('../3. 초기데이터/0. 데이터/simpson 회귀분석 데이터.csv', index=False)\n",
    "\n",
    "df_save = pd.concat([df_LDL_C, df_dnn_predicted], axis = 1)\n",
    "df_save.to_csv('../3. 초기데이터/0. 데이터/dnn 회귀분석 데이터.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e8d0157c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3 4 3 ... 2 2 2]\n",
      "결측치 갯수:  0\n",
      "[3. 4. 2. ... 2. 2. 2.]\n",
      "결측치 갯수:  0\n",
      "[3. 4. 2. ... 3. 2. 2.]\n",
      "결측치 갯수:  0\n",
      "[3. 4. 2. ... 2. 2. 2.]\n",
      "결측치 갯수:  0\n",
      "[3. 4. 2. ... 3. 2. 2.]\n",
      "결측치 갯수:  0\n"
     ]
    }
   ],
   "source": [
    "'''교차분석 데이터 생성'''\n",
    "# 분류하는 함수 정의\n",
    "def convert(data):\n",
    "    error_count = 0 # 결측치 측정 카운터\n",
    "    for x in range(0,len(data)):\n",
    "        if (data[x] < 70.0):\n",
    "            data[x] = int(1)\n",
    "        elif (data[x] >= 70.0 and data[x] < 100.0):\n",
    "            data[x] = 2\n",
    "        elif (data[x] >= 100.0 and data[x] < 130.0):\n",
    "            data[x] = 3\n",
    "        elif (data[x] >= 130.0 and data[x] < 160.0):\n",
    "            data[x] = 4\n",
    "        elif (data[x] >= 160.0 and data[x] < 190.0):\n",
    "            data[x] = 5\n",
    "        elif (data[x] >= 190.0):\n",
    "            data[x] = 6\n",
    "        else:\n",
    "            error_count += 1\n",
    "    print(data)\n",
    "    print(\"결측치 갯수: \", error_count)\n",
    "    return data\n",
    "\n",
    "\n",
    "# 변환하기\n",
    "cross_LDL_C = convert(LDL_C_data)\n",
    "cross_LDL_C = pd.DataFrame(cross_LDL_C ,columns=['LDL_C_predicted_cross'])\n",
    "\n",
    "cross_fridewald = convert(fridewald_data)\n",
    "cross_fridewald = pd.DataFrame(cross_fridewald ,columns=['fridewald_predicted_cross'])\n",
    "\n",
    "cross_marin = convert(marin_data)\n",
    "cross_marin = pd.DataFrame(cross_marin ,columns=['marin_predicted_cross'])\n",
    "\n",
    "cross_simpson = convert(simpson_data)\n",
    "cross_simpson = pd.DataFrame(cross_simpson ,columns=['simpson_predicted_cross'])\n",
    "\n",
    "cross_dnn = convert(dnn_data)\n",
    "cross_dnn = pd.DataFrame(cross_dnn ,columns=['dnn_predicted_cross'])\n",
    "\n",
    "# 유형별로 교차분석 데이터 저장\n",
    "df_save = pd.concat([cross_LDL_C, cross_fridewald], axis = 1)\n",
    "df_save.to_csv('fridewald 교차분석 데이터.csv', index=False)\n",
    "\n",
    "df_save = pd.concat([cross_LDL_C, cross_marin], axis = 1)\n",
    "df_save.to_csv('marin 교차분석 데이터.csv', index=False)\n",
    "\n",
    "df_save = pd.concat([cross_LDL_C, cross_simpson], axis = 1)\n",
    "df_save.to_csv('simpson 교차분석 데이터.csv', index=False)\n",
    "\n",
    "df_save = pd.concat([cross_LDL_C, cross_dnn], axis = 1)\n",
    "df_save.to_csv('dnn 교차분석 데이터.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "b2d8ce73",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''분류일치 데이터 생성'''\n",
    "# TG 변환하기\n",
    "error_count = 0 # 결측치 측정 카운터\n",
    "for x in range(0,len(TG_data)):\n",
    "    if (TG_data[x] >= 1.0 and TG_data[x] < 50.0):\n",
    "        TG_data[x] = 1\n",
    "    elif (TG_data[x] >= 50.0 and TG_data[x] < 100.0):\n",
    "        TG_data[x] = 50\n",
    "    elif (TG_data[x] >= 100.0 and TG_data[x] < 150.0):\n",
    "        TG_data[x] = 100\n",
    "    elif (TG_data[x] >= 150.0 and TG_data[x] < 200.0):\n",
    "        TG_data[x] = 150\n",
    "    elif (TG_data[x] >= 200.0 and TG_data[x] < 300.0):\n",
    "        TG_data[x] = 200\n",
    "    elif (TG_data[x] >= 300.0 and TG_data[x] < 400.0):\n",
    "        TG_data[x] = 300\n",
    "    elif (TG_data[x] >= 400.0 and TG_data[x] < 500.0):\n",
    "        TG_data[x] = 400\n",
    "    elif (TG_data[x] >= 500.0 and TG_data[x] < 600.0):\n",
    "        TG_data[x] = 500\n",
    "    elif (TG_data[x] >= 600.0 and TG_data[x] < 700.0):\n",
    "        TG_data[x] = 600\n",
    "    elif (TG_data[x] >= 700.0 and TG_data[x] < 800.0):\n",
    "        TG_data[x] = 800\n",
    "    elif (TG_data[x] >= 800.0 and TG_data[x] < 900.0):\n",
    "        TG_data[x] = 900\n",
    "    else:\n",
    "        error_count += 1\n",
    "\n",
    "classify_TG = pd.DataFrame(TG_data,columns=['TG_classify'])\n",
    "\n",
    "# 분류 일치 여부 확인\n",
    "def classification(data):\n",
    "    error_count = 0 # 결측치 측정 카운터\n",
    "    classify = [] # 분류 일치여부\n",
    "    for i in range(0, len(data[:,1])):\n",
    "        if (data[i,0] == data[i,1]):\n",
    "            classify.append(0)\n",
    "        elif (data[i,0] != data[i,1]):\n",
    "            classify.append(1)\n",
    "        else:\n",
    "            error_count += 1\n",
    "    #print(classify)\n",
    "    #print(\"결측치 갯수: \", error_count)\n",
    "    return classify\n",
    "\n",
    "read_data = pd.read_csv('fridewald 교차분석 데이터.csv').to_numpy()\n",
    "classify_fridewald = classification(read_data)\n",
    "classify_fridewald = pd.DataFrame(classify_fridewald,columns=['fridewald_predicted_classify'])\n",
    "\n",
    "read_data = pd.read_csv('marin 교차분석 데이터.csv').to_numpy()\n",
    "classify_marin = classification(read_data)\n",
    "classify_marin = pd.DataFrame(classify_marin,columns=['marin_predicted_classify'])\n",
    "\n",
    "read_data = pd.read_csv('simpson 교차분석 데이터.csv').to_numpy()\n",
    "classify_simpson = classification(read_data)\n",
    "classify_simpson = pd.DataFrame(classify_simpson,columns=['simpson_predicted_classify'])\n",
    "\n",
    "read_data = pd.read_csv('dnn 교차분석 데이터.csv').to_numpy()\n",
    "classify_dnn = classification(read_data)\n",
    "classify_dnn = pd.DataFrame(classify_dnn,columns=['dnn_predicted_classify'])\n",
    "\n",
    "# 유형별로 분류일치 데이터 저장\n",
    "\n",
    "df_save = pd.concat([classify_TG, classify_fridewald], axis = 1)\n",
    "df_save.to_csv('fridewald 분류일치 데이터.csv', index=False)\n",
    "\n",
    "df_save = pd.concat([classify_TG, classify_marin], axis = 1)\n",
    "df_save.to_csv('marin 분류일치 데이터.csv', index=False)\n",
    "\n",
    "df_save = pd.concat([classify_TG, classify_simpson], axis = 1)\n",
    "df_save.to_csv('simpson 분류일치 데이터.csv', index=False)\n",
    "\n",
    "df_save = pd.concat([classify_TG, classify_dnn], axis = 1)\n",
    "df_save.to_csv('dnn 분류일치 데이터.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aae08bec",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensorflow-gpu",
   "language": "python",
   "name": "tensor-gpu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
